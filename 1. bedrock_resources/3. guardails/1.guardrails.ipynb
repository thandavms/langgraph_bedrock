{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_client = boto3.client('bedrock')\n",
    "runtime_client = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardrail_id = '7l2cg7arccsk'\n",
    "guardrail_version = 'DRAFT'\n",
    "modelID = 'anthropic.claude-3-haiku-20240307-v1:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Is the AB503 Product a better investment than the S&P 500?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "payload = {\n",
    "    \"modelId\": modelID,\n",
    "    \"contentType\": \"application/json\",\n",
    "    \"accept\": \"application/json\",\n",
    "    \"body\": {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the payload to bytes\n",
    "body_bytes = json.dumps(payload['body']).encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Guardrail with invoke model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the model\n",
    "response = runtime_client.invoke_model(\n",
    "    body = body_bytes,\n",
    "    contentType = payload['contentType'],\n",
    "    accept = payload['accept'],\n",
    "    modelId = payload['modelId'],\n",
    "    guardrailIdentifier = guardrail_id, \n",
    "    guardrailVersion =guardrail_version, \n",
    "    trace = \"ENABLED\"\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "response_body = response['body'].read().decode('utf-8')\n",
    "print(json.dumps(json.loads(response_body), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_UNIT = 1000 # characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_severe_violations(violations):\n",
    "    # When guardrail intervenes either the action on the request is BLOCKED or NONE\n",
    "    # Here we check how many of the violations lead to blocking the request\n",
    "    severe_violations = [violation['action']=='BLOCKED' for violation in violations]\n",
    "    return sum(severe_violations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_policy_assessement_blocked(assessments):\n",
    "    # While creating the guardrail you could specify multiple types of policies.\n",
    "    # At the time of assessment all the policies should be checked for potential violations\n",
    "    # If there is even 1 violation that blocks the request, the entire request is blocked\n",
    "    blocked = []\n",
    "    for assessment in assessments:\n",
    "        if 'topicPolicy' in assessment:\n",
    "            blocked.append(check_severe_violations(assessment['topicPolicy']['topics']))\n",
    "        if 'wordPolicy' in assessment:\n",
    "            if 'customWords' in assessment['wordPolicy']:\n",
    "                blocked.append(check_severe_violations(assessment['wordPolicy']['customWords']))\n",
    "            if 'managedWordLists' in assessment['wordPolicy']:\n",
    "                blocked.append(check_severe_violations(assessment['wordPolicy']['managedWordLists']))\n",
    "        if 'sensitiveInformationPolicy' in assessment:\n",
    "            if 'piiEntities' in assessment['sensitiveInformationPolicy']:\n",
    "                blocked.append(check_severe_violations(assessment['sensitiveInformationPolicy']['piiEntities']))\n",
    "            if 'regexes' in assessment['sensitiveInformationPolicy']:\n",
    "                blocked.append(check_severe_violations(assessment['sensitiveInformationPolicy']['regexes']))\n",
    "        if 'contentPolicy' in assessment:\n",
    "            blocked.append(check_severe_violations(assessment['contentPolicy']['filters']))\n",
    "    severe_violation_count = sum(blocked)\n",
    "    print(f'\\033[91m::Guardrail:: {severe_violation_count} severe violations detected\\033[0m')\n",
    "    return severe_violation_count>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_guardrail(text, text_source_type, guardrail_id, guardrail_version=\"DRAFT\"):\n",
    "    print(f'\\n\\n\\033[91m::Guardrail:: Applying guardrail with {(len(text)//TEXT_UNIT)+1} text units\\033[0m\\n')\n",
    "    response = runtime_client.apply_guardrail(\n",
    "        guardrailIdentifier=guardrail_id,\n",
    "        guardrailVersion=guardrail_version, \n",
    "        source=text_source_type, # can be 'INPUT' or 'OUTPUT'\n",
    "        content=[{\"text\": {\"text\": text}}]\n",
    "    )\n",
    "    if response['action'] == 'GUARDRAIL_INTERVENED':\n",
    "        is_blocked = is_policy_assessement_blocked(response['assessments'])\n",
    "        alternate_text = ' '.join([output['text'] for output in response['outputs']])\n",
    "        return is_blocked, alternate_text, response\n",
    "    else:\n",
    "        # Return the default response in case of no guardrail intervention\n",
    "        return False, text, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_conversation(messages,\n",
    "                        system_prompts):\n",
    "    \n",
    "    response = runtime_client.converse_stream(\n",
    "        modelId=modelID,\n",
    "        messages=messages,\n",
    "        system=system_prompts\n",
    "    )\n",
    "\n",
    "    stream = response.get('stream')\n",
    "    full_text = \"\"\n",
    "    buffer_text = \"\"\n",
    "    applied_guardrails = []\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            if 'messageStart' in event:\n",
    "                print(f\"\\nRole: {event['messageStart']['role']}\")\n",
    "\n",
    "            if 'contentBlockDelta' in event:\n",
    "                new_text = event['contentBlockDelta']['delta']['text']\n",
    "\n",
    "                if len(buffer_text + new_text) > TEXT_UNIT:\n",
    "                    is_blocked, alt_text, guardrail_response = apply_guardrail(buffer_text, \"OUTPUT\", guardrail_id, guardrail_version)\n",
    "                    if is_blocked:\n",
    "                        event['messageStop'] = {\n",
    "                            'stopReason': guardrail_response['action'], \n",
    "                            'output': alt_text,\n",
    "                            'assessments': guardrail_response['assessments'],\n",
    "                        }\n",
    "                        full_text = alt_text\n",
    "                    else:\n",
    "                        full_text += alt_text\n",
    "                    print(alt_text, end=\"\")\n",
    "                    applied_guardrails.append(guardrail_response)\n",
    "                    buffer_text = new_text\n",
    "                else: \n",
    "                    buffer_text += new_text\n",
    "\n",
    "            if 'messageStop' in event:\n",
    "                if event['messageStop']['stopReason'] == 'GUARDRAIL_INTERVENED':\n",
    "                    print(f\"\\nStop reason: {event['messageStop']['stopReason']}\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"\\nStop reason: {event['messageStop']['stopReason']}\")\n",
    "                    is_blocked, alt_text, guardrail_response = apply_guardrail(buffer_text, \"OUTPUT\", guardrail_id, guardrail_version)\n",
    "                    if is_blocked:\n",
    "                        print(alt_text)\n",
    "                        if 'metadata' not in event:\n",
    "                            event['metadata'] = {}\n",
    "                        event['metadata']['guardrails_usage'] = guardrail_response['usage']\n",
    "                        applied_guardrails.append(guardrail_response)\n",
    "\n",
    "            if 'metadata' in event:\n",
    "                metadata = event['metadata']\n",
    "                if 'usage' in metadata:\n",
    "                    print(\"\\nToken usage\")\n",
    "                    print(f\"Input tokens: {metadata['usage']['inputTokens']}\")\n",
    "                    print(\n",
    "                        f\":Output tokens: {metadata['usage']['outputTokens']}\")\n",
    "                    print(f\":Total tokens: {metadata['usage']['totalTokens']}\")\n",
    "                    print(f\":Total text units: {(len(full_text)//TEXT_UNIT)+1}\")\n",
    "                if 'metrics' in event['metadata']:\n",
    "                    print(\n",
    "                        f\"Latency: {metadata['metrics']['latencyMs']} milliseconds\")\n",
    "                if 'guardrails_usage' in event['metadata']:\n",
    "                    print(event['metadata']['guardrails_usage'])\n",
    "    return full_text, applied_guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = \"List 3 names of prominent CEOs and later tell me what is a bank and what are the benefits of opening a savings account?\"\n",
    "prompt = \"Tell me about why financial independence is important and only at the very end ask the question if you can help me to invest after retirement?\"\n",
    "\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": prompt}]\n",
    "}\n",
    "messages = [message]\n",
    "\n",
    "# System prompts.\n",
    "system_prompt = \"\"\"You are an assistant that helps with tasks from users. Be as elaborate as possible\"\"\"\n",
    "system_prompts = [{\"text\" : system_prompt}]\n",
    "\n",
    "full_text, applied_guardrails = stream_conversation(messages, system_prompts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

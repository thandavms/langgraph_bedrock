{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "tavily_api_key = os.getenv('TAVILY_API_KEY')\n",
    "model_id = os.getenv('MODEL_ID')\n",
    "aws_region = os.getenv('AWS_REGION')\n",
    "bedrock_kb_id = os.getenv('BEDROCK_KB_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model - Agent Brain\n",
    "from langchain_aws import ChatBedrock\n",
    "llm = ChatBedrock(model=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### State - The schema of the State will be the input schema to all Nodes and Edges in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph State\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    route_path: str\n",
    "    web_search: str\n",
    "    kb_search: str\n",
    "    final_blog: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "def search_web(state: State):\n",
    "    print(\"SEARHING WEB\")\n",
    "    search_tool = TavilySearchResults(max_results=2)\n",
    "    web_results = search_tool.invoke(state[\"query\"])\n",
    "    return {\"web_search\": web_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "def query_knowledge_base(state: State):\n",
    "    \"\"\"Query the knowledge base for information related to Agents and Agentic workflow\n",
    "    \n",
    "    Args:\n",
    "        query: The query string to search for\n",
    "    \"\"\"\n",
    "    bedrock_agent = boto3.client('bedrock-agent-runtime', region_name = aws_region)\n",
    "    print(\"QUERYING KB\")\n",
    "\n",
    "\n",
    "    response = bedrock_agent.retrieve_and_generate(\n",
    "        input={\n",
    "            \"text\": state[\"query\"]  # Your query text goes here\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            \"type\": \"KNOWLEDGE_BASE\",\n",
    "            \"knowledgeBaseConfiguration\": {\n",
    "                \"knowledgeBaseId\": bedrock_kb_id,\n",
    "                \"modelArn\": model_id,\n",
    "                \"retrievalConfiguration\": {\n",
    "                    \"vectorSearchConfiguration\": {\n",
    "                        \"numberOfResults\": 5\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    kb_results = response['output']['text']\n",
    "    return {\"kb_search\" : kb_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogger(state: State):\n",
    "    print(\"WRITING BLOG\")\n",
    "    if 'kb_search' in state:\n",
    "        prompt = f\"\"\" Your job is to create a blog title and a one paragraph blog from this content: {state['kb_search']}\"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\" Your job is to create a blog title and a one paragraph blog from this content: {state['web_search']}\"\"\"\n",
    "    final_answer = llm.invoke(prompt)           \n",
    "    return {\"final_blog\": final_answer.content}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_node(state:State):\n",
    "    print(\"ROUTER\")\n",
    "    prompt = f\"\"\" Your job is to identify the topic of the query in {state['query']} if the topic is about agents, answer \"agent\" otherwise answer as \"other\".  just provide the answer.  ignore any preambles\"\"\"\n",
    "    route_decision = llm.invoke(prompt)           \n",
    "    return {\"route_path\": route_decision.content}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_decision(state: State):\n",
    "    if state['route_path'] == 'agent':\n",
    "        return \"kb\"\n",
    "    else:\n",
    "        return \"web\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build workflow\n",
    "router = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "router.add_node(\"route\", route_node)\n",
    "router.add_node(\"search_kb\", query_knowledge_base)\n",
    "router.add_node(\"search_web\", search_web)\n",
    "router.add_node(\"blog_writer\", blogger)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "router.add_edge(START, \"route\")\n",
    "router.add_conditional_edges(\"route\", route_decision, {\"kb\": \"search_kb\", \"web\" : \"search_web\"})\n",
    "router.add_edge(\"search_kb\", \"blog_writer\")\n",
    "router.add_edge(\"search_web\", \"blog_writer\")\n",
    "\n",
    "router.add_edge(\"blog_writer\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compile Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = router.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import Image, display\n",
    "\n",
    "requests.adapters.DEFAULT_TIMEOUT = 30  # Increase from default 10 seconds\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Invoke Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = agent.invoke({\"query\": \"who is usain bolt?\"})\n",
    "state['final_blog']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
